{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (4209, 378)\n",
      "Shape test: (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "# read datasets\n",
    "train = pd.read_csv('data_fun/data/train.csv')\n",
    "test = pd.read_csv('data_fun/data/test.csv')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object':\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This step is huge!\n",
    "from sklearn.decomposition import PCA, FastICA \n",
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_train = train[\"y\"]\n",
    "y_mean = np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-r2_metric:0.005423\ttest-r2_metric:0.004084\n",
      "[50]\ttrain-r2_metric:0.234394\ttest-r2_metric:0.224742\n",
      "[100]\ttrain-r2_metric:0.3753\ttest-r2_metric:0.358211\n",
      "[150]\ttrain-r2_metric:0.462841\ttest-r2_metric:0.438891\n",
      "[200]\ttrain-r2_metric:0.517671\ttest-r2_metric:0.487574\n",
      "[250]\ttrain-r2_metric:0.552546\ttest-r2_metric:0.516984\n",
      "[300]\ttrain-r2_metric:0.575248\ttest-r2_metric:0.534909\n",
      "[350]\ttrain-r2_metric:0.592353\ttest-r2_metric:0.545639\n",
      "[400]\ttrain-r2_metric:0.606735\ttest-r2_metric:0.55194\n",
      "[450]\ttrain-r2_metric:0.618064\ttest-r2_metric:0.555598\n",
      "[500]\ttrain-r2_metric:0.6285\ttest-r2_metric:0.557612\n",
      "[550]\ttrain-r2_metric:0.637139\ttest-r2_metric:0.558715\n",
      "[600]\ttrain-r2_metric:0.644767\ttest-r2_metric:0.559442\n",
      "[650]\ttrain-r2_metric:0.651455\ttest-r2_metric:0.559638\n",
      "[700]\ttrain-r2_metric:0.657961\ttest-r2_metric:0.55957\n"
     ]
    }
   ],
   "source": [
    "y_train = train[\"y\"]\n",
    "y_mean = np.mean(y_train)\n",
    "()# mmm, xgboost, loved by everyone ^-^\n",
    "import xgboost as xgb\n",
    "\n",
    "# prepare dict of params for xgboost to run with\n",
    "xgb_params = {\n",
    "    'n_trees': 500, \n",
    "    'eta': 0.005,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.95,\n",
    "    'objective': 'reg:linear',\n",
    "    #'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "# form DMatrices for Xgboost training\n",
    "dtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\n",
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "\n",
    "\n",
    "def r2_metric(preds, dtrain):\n",
    "    \"\"\"Self defined evaluation obj\"\"\"\n",
    "    from sklearn.metrics import r2_score\n",
    "    return 'r2_metric', r2_score(dtrain.get_label(), preds)\n",
    "\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1000, # increase to have better results (~700)\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose_eval=50, \n",
    "                   show_stdv=False,\n",
    "                   feval = r2_metric,\n",
    "                   maximize = True\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.633945009942\n"
     ]
    }
   ],
   "source": [
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "\n",
    "# now fixed, correct calculation\n",
    "print(r2_score(dtrain.get_label(), model.predict(dtrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions and save results\n",
    "y_pred = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n",
    "output.to_csv('xgboost-depth{}-pca-ica.csv'.format(xgb_params['max_depth']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'xgboost' from '/usr/local/lib/python3.6/site-packages/xgboost/__init__.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramter Turning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first consider an example for \"GridSearch\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best is score is 0.98\n",
      "It is given by parameters setting:\n",
      "C: 1\n",
      "kernel: 'linear'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = GridSearchCV(svr, parameters,verbose= 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Best is score is {}'.format(score))\n",
    "print('It is given by parameters setting:')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "clf.best_params_\n",
    "# clf. to see how to extract useful info then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at our problem. The default parameter is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 550, \n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.95,\n",
    "    'objective': 'reg:linear',\n",
    "    #'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    #'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use grid search to find good parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=1, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0 \n",
      "[CV]  reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=1, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0, total=   1.8s\n",
      "[CV] reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=1, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0 \n",
      "[CV]  reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=1, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0, total=   2.5s\n",
      "[CV] reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=1, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0 \n",
      "[CV]  reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=1, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0, total=   2.6s\n",
      "[CV] reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=5, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0 \n",
      "[CV]  reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=5, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0, total=   2.7s\n",
      "[CV] reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=5, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0 \n",
      "[CV]  reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=5, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0, total=   2.6s\n",
      "[CV] reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=5, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0 \n",
      "[CV]  reg_alpha=0, colsample_bytree=0.6, learning_rate=0.01, min_child_weight=5, subsample=0.6, reg_lambda=1, max_depth=4, gamma=0, total=   2.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.537761432887\n",
      "colsample_bytree: 0.6\n",
      "gamma: 0\n",
      "learning_rate: 0.01\n",
      "max_depth: 4\n",
      "min_child_weight: 5\n",
      "reg_alpha: 0\n",
      "reg_lambda: 1\n",
      "subsample: 0.6\n",
      "[0]\ttrain-r2_metric:-61.2333\ttest-r2_metric:-61.3924\n",
      "[50]\ttrain-r2_metric:-22.1245\ttest-r2_metric:-22.1844\n",
      "[100]\ttrain-r2_metric:-7.77013\ttest-r2_metric:-7.79586\n",
      "[150]\ttrain-r2_metric:-2.49104\ttest-r2_metric:-2.5084\n",
      "[200]\ttrain-r2_metric:-0.544446\ttest-r2_metric:-0.567541\n",
      "[250]\ttrain-r2_metric:0.179741\ttest-r2_metric:0.146239\n",
      "[300]\ttrain-r2_metric:0.454008\ttest-r2_metric:0.410373\n",
      "[350]\ttrain-r2_metric:0.563022\ttest-r2_metric:0.508223\n",
      "[400]\ttrain-r2_metric:0.609867\ttest-r2_metric:0.544423\n",
      "[450]\ttrain-r2_metric:0.633036\ttest-r2_metric:0.557212\n",
      "[500]\ttrain-r2_metric:0.647178\ttest-r2_metric:0.561282\n",
      "[550]\ttrain-r2_metric:0.657793\ttest-r2_metric:0.562053\n",
      "541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoyuan/assignment1/.env/local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train = train[\"y\"]\n",
    "y_mean = np.mean(y_train)\n",
    "()# mmm, xgboost, loved by everyone ^-^\n",
    "import xgboost as xgb\n",
    "\n",
    "boost = xgb.XGBRegressor(**xgb_params)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    # n_estimators\n",
    "    'learning_rate': [0.01],#, 0.015,0.05],\n",
    "    'gamma': [0],#,0.1, 0.5,0.9],\n",
    "    'max_depth': [4],#, 9],\n",
    "    'min_child_weight': [1,5],\n",
    "    \"subsample\": [0.6],#,0.8,1],\n",
    "    'colsample_bytree': [0.6],#,0.8,1],\n",
    "    'reg_alpha' : [0], \n",
    "    'reg_lambda' : [1],\n",
    "}\n",
    "reg = GridSearchCV(boost, parameters, n_jobs=1, cv=3, verbose = 2)\n",
    "reg.fit(train.drop('y', axis=1).as_matrix(), y_train)\n",
    "\n",
    "best_parameters, score, _ = max(reg.grid_scores_, key=lambda x: x[1])\n",
    "print(score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "pickle.dump( reg.best_params_, open(\"bestpara.p\", \"wb\" ))\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\n",
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "\n",
    "def r2_metric(preds, dtrain):\n",
    "    \"\"\"Self defined evaluation obj\"\"\"\n",
    "    from sklearn.metrics import r2_score\n",
    "    return 'r2_metric', r2_score(dtrain.get_label(), preds)\n",
    "\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(reg.best_params_, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1000, # increase to have better results (~700)\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose_eval=50, \n",
    "                   show_stdv=False,\n",
    "                   feval = r2_metric,\n",
    "                   maximize = True\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(reg.best_params_, silent=0), dtrain, num_boost_round=num_boost_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump( reg.best_params_, open(\"bestpara.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b2a640a5b79b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"bestpara.p\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_proto\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[0mproto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mproto\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"unsupported pickle protocol: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPROTO\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unsupported pickle protocol: 3"
     ]
    }
   ],
   "source": [
    "pickle.load( open( \"bestpara.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (4209, 378)\n",
      "Shape test: (4209, 377)\n",
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits"
     ]
    }
   ],
   "source": [
    "favorite_color = { \"lion\": \"yellow\", \"kitty\": \"red\" }\n",
    "pickle.dump( favorite_color, open( \"save.p\", \"wb\" ) )\n",
    "\n",
    "pickle.load( open( \"save.p\", \"rb\" ) )\n",
    "\n",
    "# read datasets\n",
    "train = pd.read_csv('data_fun/data/train.csv')\n",
    "test = pd.read_csv('data_fun/data/test.csv')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object':\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n",
    "\n",
    "# This step is huge!\n",
    "from sklearn.decomposition import PCA, FastICA \n",
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_train = train[\"y\"]\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "y_train = train[\"y\"]\n",
    "y_mean = np.mean(y_train)\n",
    "()# mmm, xgboost, loved by everyone ^-^\n",
    "import xgboost as xgb\n",
    "xgb_params = {\n",
    "    'n_estimators': 550, \n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.95,\n",
    "    'objective': 'reg:linear',\n",
    "    #'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    #'silent': 1\n",
    "}\n",
    "\n",
    "boost = xgb.XGBRegressor(**xgb_params)\n",
    "\n",
    "parameters = {\n",
    "    # n_estimators\n",
    "    'learning_rate': [0.01, 0.015,0.05],\n",
    "    'gamma': [0,0.1,0.5,0.9],\n",
    "    'max_depth': [4, 9],\n",
    "    'min_child_weight': [1,5],\n",
    "    \"subsample\": [0.6,0.8,1],\n",
    "    'colsample_bytree': [0.6,0.8,1],\n",
    "    'reg_alpha' : [0], \n",
    "    'reg_lambda' : [1],\n",
    "}\n",
    "reg = GridSearchCV(boost, parameters, n_jobs=1, cv=3, verbose = 1)\n",
    "reg.fit(train.drop('y', axis=1).as_matrix(), y_train)\n",
    "\n",
    "best_parameters, score, _ = max(reg.grid_scores_, key=lambda x: x[1])\n",
    "print(score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "pickle.dump( reg.best_params_, open(\"bestpara.p\", \"wb\" ))\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(reg.best_params_, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1000, # increase to have better results (~700)\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose_eval=50, \n",
    "                   show_stdv=False,\n",
    "                   feval = r2_metric,\n",
    "                   maximize = True\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(reg.best_params_, silent=0), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "\n",
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "\n",
    "# now fixed, correct calculation\n",
    "print(r2_score(dtrain.get_label(), model.predict(dtrain)))\n",
    "\n",
    "# make predictions and save results\n",
    "y_pred = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n",
    "output.to_csv('xgboost-depth{}-pca-ica.csv'.format(xgb_params['max_depth']), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
