{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_with_val():\n",
    "    print('generating data......')\n",
    "    # read datasets\n",
    "    train_total = pd.read_csv('../data/train.csv') ## Shape train: (4209, 378)\n",
    "    X_test = pd.read_csv('../data/test.csv') ## Shape test: (4209, 377)\n",
    "\n",
    "    # Shuffle data\n",
    "    l = [x for x in range(4209)]\n",
    "    np.random.shuffle(l)\n",
    "    train_total = train_total.iloc[l]\n",
    "\n",
    "    # split data\n",
    "    ratio = 0.7\n",
    "    threshold = int(ratio*4209)\n",
    "    X_train = train_total.iloc[range(threshold)] \n",
    "    val = train_total.iloc[range(threshold, 4209)]\n",
    "    y_train = X_train['y']\n",
    "    X_train = X_train.drop('y', axis = 1)\n",
    "    y_val = val['y']\n",
    "    X_val = val.drop('y', axis = 1)\n",
    "\n",
    "    # process type\n",
    "    for c in train_total.columns:\n",
    "        if train_total[c].dtype == 'object':\n",
    "            lbl = LabelEncoder() \n",
    "            lbl.fit(list(train_total[c].values) + list(X_test[c].values)) \n",
    "            X_train[c] = lbl.transform(list(X_train[c].values))\n",
    "            X_val[c] = lbl.transform(list(X_val[c].values))\n",
    "            X_test[c] = lbl.transform(list(X_test[c].values))\n",
    "\n",
    "    # shape        \n",
    "    print('Shape X_train:', X_train.shape)\n",
    "    print('Shape X_test:', X_test.shape)\n",
    "    print('Shape X_val:', X_val.shape )\n",
    "    return X_train, y_train, X_val, y_val, X_test\n",
    "\n",
    "def data():\n",
    "    print('generating data......')\n",
    "    # read datasets\n",
    "    X_train = pd.read_csv('../data/train.csv') ## Shape train: (4209, 378)\n",
    "    X_test = pd.read_csv('../data/test.csv') ## Shape test: (4209, 377)\n",
    "\n",
    "    # Shuffle data\n",
    "    l = [x for x in range(4209)]\n",
    "    np.random.shuffle(l)\n",
    "    X_train = X_train.iloc[l]\n",
    "\n",
    "    y_train = X_train['y']\n",
    "    X_train = X_train.drop('y', axis = 1)\n",
    "\n",
    "    # process type\n",
    "    for c in X_train.columns:\n",
    "        if X_train[c].dtype == 'object':\n",
    "            lbl = LabelEncoder() \n",
    "            lbl.fit(list(X_train[c].values) + list(X_test[c].values)) \n",
    "            X_train[c] = lbl.transform(list(X_train[c].values))\n",
    "            X_test[c] = lbl.transform(list(X_test[c].values))\n",
    "\n",
    "    # shape        \n",
    "    print('Shape X_train:', X_train.shape)\n",
    "    print('Shape X_test:', X_test.shape)\n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "\n",
    "def turn():\n",
    "    boost = xgb.XGBRegressor()\n",
    "    print('trunning model.....')\n",
    "    parameters = {'learning_rate': [0.005],\n",
    "                  'gamma': [0,0.5],\n",
    "                  'max_depth': [4, 9],\n",
    "                  'min_child_weight': [1,5],\n",
    "                  \"subsample\": [0.6,1],\n",
    "                  'colsample_bytree': [0.6,1],\n",
    "                 }\n",
    "    reg = RandomizedSearchCV(boost, parameters, n_jobs=8, cv=3, verbose = 1)\n",
    "    reg.fit(X_train, y_train)\n",
    "    best_parameters, score, _ = max(reg.grid_scores_, key=lambda x: x[1])\n",
    "    print(score)\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    pickle.dump( reg.best_params_, open(\"bestpara.p\", \"wb\" ))\n",
    "    return reg.best_params_\n",
    "    \n",
    "def gradient_boost(trun = False, cv = False):\n",
    "    print('trainning model......')\n",
    "    xgb_params = {'n_estimators': 600, \n",
    "                  'learning_rate': 0.05,\n",
    "                  'max_depth': 4,\n",
    "                  'subsample': 0.95,\n",
    "                  'objective': 'reg:linear',\n",
    "                  #'eval_metric': 'rmse',\n",
    "                  'base_score': np.mean(y_train),\n",
    "                  #'silent': 1\n",
    "                 }\n",
    "    if trun:\n",
    "        xgb_params = turn()\n",
    "    boost = xgb.XGBRegressor(**xgb_params)\n",
    "    boost.fit(X_train, y_train)\n",
    "    print('model trained, computing score.....')\n",
    "    if cv:\n",
    "        scores = cross_val_score(boost, X_train, y_train, cv=3, scoring = 'neg_mean_squared_error')\n",
    "        print(\"CV score:\", np.sqrt(np.mean(-scores)))\n",
    "    else:\n",
    "        print('mse:', mean_squared_error(boost.predict(X_val), y_val))\n",
    "    pickle.dump( boost, open( \"boost.p\", \"wb\" ) )\n",
    "    return boost\n",
    "\n",
    "def NN():\n",
    "    enc = OneHotEncoder(dtype = 'float32')\n",
    "    enc.fit(X_train)  \n",
    "    X  = enc.transform(X_train)\n",
    "    y = y_train/(np.max(y_train))\n",
    "    y = np.float32(y.as_matrix())\n",
    "    X = Variable(torch.from_numpy(X.toarray()))\n",
    "    y = Variable(torch.from_numpy(y))\n",
    "    \n",
    "    _,n0 = X.data.numpy().shape\n",
    "    n1,n2,n3 = 30, 20,1 # layer numbers\n",
    "    net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(n0, n1),\n",
    "        torch.nn.ReLU(),    \n",
    "        torch.nn.Linear(n1, n2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(n2,n3),\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "    loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "    for t in range(1000):\n",
    "        prediction = net(X)     # input X and predict based on X\n",
    "        loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "        if t % 50 ==0: print(loss)\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "\n",
    "    return net\n",
    "\n",
    "def output():\n",
    "    print('generating output file......')\n",
    "    y_pred = model.predict(X_test)\n",
    "    output = pd.DataFrame({'id': X_test['ID'].astype(np.int32), 'y': y_pred})\n",
    "    output.to_csv('submition.csv', index=False)\n",
    "    print('File upgraded!')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating data......\n",
      "Shape X_train: (4209, 377)\n",
      "Shape X_test: (4209, 377)\n",
      "trainning model......\n",
      "model trained, computing score.....\n",
      "CV score: 8.79750964363\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# gloable name: X_train,y_train,X_val,y_val, X_test, modle #\n",
    "############################################################\n",
    "\n",
    "#X_train,y_train,X_val,y_val, X_test = data_with_val()\n",
    "X_train,y_train, X_test = data()\n",
    "\n",
    "#y_train = y_train/(np.max(y_train))\n",
    "model1 = gradient_boost(cv = True)\n",
    "#model2 = NN()\n",
    "#output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boost = pickle.load( open( \"boost.p\", \"rb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
