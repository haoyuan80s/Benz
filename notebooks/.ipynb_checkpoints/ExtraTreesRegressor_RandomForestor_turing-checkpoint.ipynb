{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    print('generating data......')\n",
    "    # read datasets\n",
    "    X_train = pd.read_csv('../data/train.csv') ## Shape train: (4209, 378)\n",
    "    X_test = pd.read_csv('../data/test.csv') ## Shape test: (4209, 377)\n",
    "\n",
    "    # Shuffle data\n",
    "    l = [x for x in range(4209)]\n",
    "    np.random.shuffle(l)\n",
    "    X_train = X_train.iloc[l]\n",
    "\n",
    "    y_train = X_train['y']\n",
    "    X_train = X_train.drop('y', axis = 1)\n",
    "\n",
    "    # process type\n",
    "    for c in X_train.columns:\n",
    "        if X_train[c].dtype == 'object':\n",
    "            lbl = LabelEncoder() \n",
    "            lbl.fit(list(X_train[c].values) + list(X_test[c].values)) \n",
    "            X_train[c] = lbl.transform(list(X_train[c].values))\n",
    "            X_test[c] = lbl.transform(list(X_test[c].values))\n",
    "\n",
    "    # shape        \n",
    "    print('Shape X_train:', X_train.shape)\n",
    "    print('Shape X_test:', X_test.shape)\n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "\n",
    "def turn():\n",
    "    boost = xgb.XGBRegressor()\n",
    "    print('trunning model.....')\n",
    "    parameters = {'learning_rate': [0.005],\n",
    "                  'gamma': [0,0.5],\n",
    "                  'max_depth': [4, 9],\n",
    "                  'min_child_weight': [1,5],\n",
    "                  \"subsample\": [0.6,1],\n",
    "                  'colsample_bytree': [0.6,1],\n",
    "                 }\n",
    "    reg = RandomizedSearchCV(boost, parameters, n_jobs=8, cv=3, verbose = 1)\n",
    "    reg.fit(X_train, y_train)\n",
    "    best_parameters, score, _ = max(reg.grid_scores_, key=lambda x: x[1])\n",
    "    print(score)\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    pickle.dump( reg.best_params_, open(\"bestpara.p\", \"wb\" ))\n",
    "    return reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating data......\n",
      "Shape X_train: (4209, 377)\n",
      "Shape X_test: (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train, X_test = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = 'ID'\n",
    "TARGET = 'y'\n",
    "NFOLDS = 4\n",
    "SEED = 0\n",
    "NROWS = None\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "TRAIN_FILE = \"{0}/train.csv\".format(DATA_DIR)\n",
    "TEST_FILE = \"{0}/test.csv\".format(DATA_DIR)\n",
    "SUBMISSION_FILE = \"{0}/sample_submission.csv\".format(DATA_DIR)\n",
    "\n",
    "x_train = np.array(X_train)\n",
    "x_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "SEED = 0\n",
    "ntrain, D = X_train.shape\n",
    "ntest, _ = X_test.shape\n",
    "NFOLDS = 4\n",
    "\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turing(clf):\n",
    "    best_err = 100000000\n",
    "    data = []\n",
    "    for _ in range(2):\n",
    "        n_estimators = int(np.random.uniform(0,900))\n",
    "        max_features = np.random.uniform(0,1)\n",
    "        max_depth = int(np.random.uniform(1,10))\n",
    "        min_samples_leaf = int(np.random.uniform(1,7))\n",
    "        params = {\n",
    "            'n_jobs': 16,\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_features': max_features,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "        }\n",
    "        model = SklearnWrapper(clf=clf, seed=SEED, params=params)\n",
    "        oof_train, oof_test = get_oof(model)\n",
    "        err = mean_squared_error(y_train, oof_train)\n",
    "        if best_err > err:\n",
    "            best_err = err\n",
    "            best_para = et_params\n",
    "        print(err,best_err, params)\n",
    "        data += [(params,err)]\n",
    "\n",
    "    pickle.dump(data,open(\"{}.p\".format(ExtraTreesRegressor),'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.6114166261 70.6114166261 {'n_jobs': 16, 'n_estimators': 222, 'max_features': 0.37109603499761, 'max_depth': 8, 'min_samples_leaf': 3, 'random_state': 0}\n",
      "70.2147482479 70.2147482479 {'n_jobs': 16, 'n_estimators': 737, 'max_features': 0.230193291236094, 'max_depth': 7, 'min_samples_leaf': 4, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "turing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'max_depth': 8,\n",
       "   'max_features': 0.37109603499761,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 222,\n",
       "   'n_jobs': 16,\n",
       "   'random_state': 0},\n",
       "  70.611416626103335),\n",
       " ({'max_depth': 7,\n",
       "   'max_features': 0.230193291236094,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 737,\n",
       "   'n_jobs': 16,\n",
       "   'random_state': 0},\n",
       "  70.214748247858381)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load( open( \"<class 'sklearn.ensemble.forest.ExtraTreesRegressor'>.p\", \"rb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
